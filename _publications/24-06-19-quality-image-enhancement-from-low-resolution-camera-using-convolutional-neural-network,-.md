---
title: "Quality Image Enhancement from Low Resolution Camera using Convolutional Neural Network, "
collection: publications
permalink: /publication/24-06-19-quality-image-enhancement-from-low-resolution-camera-using-convolutional-neural-network,-
excerpt: 'Images captured with various c ...'
date: 24-06-19
venue: '2019 7th International Conference on Information and Communication Technology (ICoICT)'
paperurl: 'https://ieeexplore.ieee.org/document/8835273'
citation: 'N. P. Patmawati, A. Arifianto and K. N. Ramadhani, &quot;Quality Image Enhancement from Low Resolution Camera using Convolutional Neural Network,&quot; 2019 7th International Conference on Information and Communication Technology (ICoICT), 2019, pp. 1-6, doi: 10.1109/ICoICT.2019.8835273.'
---
Images captured with various cameras have different qualities especially low-resolution images which generally have deficiencies in terms of quality. The uses of Convolutional Neural Network (CNN) in Super Resolution has been widely applied and has impressive performance results. It encourages the use of CNN to translate the captured images by low-resolution into a better resolution. In this paper, we propose a new architecture to perform image translation from low-resolution into a higher one using DenseNet with Skip-connections. The dataset used is taken from the DPED (DSLR-Photo Enhancement Dataset) which contains images captured from different cameras simultaneously. To get results that can be used by all camera models, a transfer learning scenario is added. Using our architecture, we were able to achieve results with average PSNR of 20,86 dB and 0,9307 SSIM which was better than the comparison architecture.

[Download paper here](https://ieeexplore.ieee.org/document/8835273)

Recommended citation: N. P. Patmawati, A. Arifianto and K. N. Ramadhani, "Quality Image Enhancement from Low Resolution Camera using Convolutional Neural Network," 2019 7th International Conference on Information and Communication Technology (ICoICT), 2019, pp. 1-6, doi: 10.1109/ICoICT.2019.8835273.